---
title:  "Avaliacao Individual - Multivariada III - LDA"
author: "Leandro Sampaio Silva"
date:   "30 de setembro de 2018"
output: html_document
---
# Linear Discriminant Analysis - LDA

```{r setup, include=FALSE}
if(!require(knitr)){install.packages('knitr')};require (knitr)
knitr::opts_chunk$set(echo = TRUE)
```

    Antes de comecar a avaliacao, perceba que ela esta dividida em cinco passos principais: "Dados", "Pressupostos", "Estimacao", "Interpretacao" e "Validacao"
    Existem linhas de comando em R que devem ser alteradas (substituir ---) e quest?es para serem respondidas (1 a 8).
    Cada passo bem executado vale 2 pontos.
    Nao se esque?a de colocar o seu nome no cabe?alho desse arquivo. Esse arquivo pode ser enviado ao meu [email](jvmelis@gmail.com) ate 30/09/2018.

### Passo 1. Leitura dos dados:
  
A) Leitura dos dados `treino`
```{r}
treino <- read.csv("dataset/estatistica8_avaliacao_training.csv", sep=",")
treino <- treino[,1:10]
```

B) Leitura dos dados `teste`
```{r}
teste <- read.csv("dataset/estatistica8_avaliacao_testing.csv", sep=",")
teste <- teste[,1:10]
```

C) Avaliar se os dois da dos (`treino` e `teste`) apresentam as mesmas propor??es
```{r}
tb_treino = table(treino$class); tb_treino; nrow(treino)
tb_teste  = table(teste$class); tb_teste; nrow(teste)
#########################################################
tb_treino_scaled <- scale(tb_treino)
tb_teste_scaled <- scale(tb_teste)
```

### Questao 1: Explique porque devemos verificar se as variaveis metricas se encontram em escalas parecidas? O que podemos fazer para que as escalas sejam semelhantes?

**R**: *Para o caso, os dados ja encontram-se em uma escala proxima, contudo, ainda necessitam estar na mesma escala pois tanto as funcoes discriminantes quanto os eixos xy necessitam que os dados estejam na mesma escala para serem visualizados/interpretados*

### Questao 2: Explique o(s) motivo(s) de usarmos um grupo de dados para treino e outro para teste?

**R**: *No caso o principal motivo seria para que a analise nao se torne enviesada em relacao ao dados observados, dividindo o dados em 2 grupos, podemos abirir uma opcao de teste apos a construcao do modelo.*

## Passo 2. Selecao de variaveis independentes Pressupostos:
  
A) Avaliar a Colienaridade das variaveis independentes.

```{r, include=FALSE}
if(!require(GGally)){install.packages("GGally")}
```

Use os graficos a seguir para fazer uma analise sintetica das relacoes:
```{r}
ggp <- GGally::ggpairs(treino, aes(color=class));print(ggp, progress = F)  
```
  
B) Avaliar a Multinormalidade das variaveis indepedentes em relacao aos grupos
```{r include=FALSE}
if(!require(heplots)){install.packages("heplots")}
```

Para isso, execute o Teste M de Box e veja se os dados seguem 
```{r}
boxM(treino[,-1],treino$class)
summary(boxM(treino[,-1],treino$class))
```

### Quest?o 3: Ha alguma inconformidade desses pressupostos? Explique.

**R**: *Nao foram encontradas inconformidades, ambas as partes da amostra apresentam um P-valor menor que 0.05, nao sendo significativos. Contudo e visivel que algumas variaveis nao seguem uma normalidade ou mesmo apresentam qualquer fator de correlacoa com as demais, abrindo espaco para a reducao da quantidade de variaveis.*

### Quest?o 4: Voce tem alguma sugestao de analise alternativa a ser feita? Explique seu ponto de vista.

**R**: *O procedimeto a ser utilizado pode ser por avaliacao das variaveis por seus pressupostos e correlacoes, mas tambem pode ser utilizado o procedimento de stepwise.*

## Passo 3. Estimacao e Avalialacao das Funcoes Discriminantes:

```{r}
if(!require(MASS)){install.packages('MASS')}
mod <- MASS::lda(class ~ . , data = data.frame(treino))
```

A) Escores das funcoes discriminantes
```{r}
mod
```

B) Correlacoes das funcoes discriminantes com as variaveis explicativas
```{r}
mod$scaling
```

C) Avalie o ajuste do modelo usando tabela confusao com os valores previstos e reais dos dados "teste". 
```{r}
pred <- predict(mod)$class
real <- treino$class
conf <- table(pred,real); conf  # Tabela confusao
```

### Quest?o 5: A partir desses resultados, existe algum espectro (b1-b9) sozinho que consegue discriminar entre os tipos florestais? Explique.

**R**: *A variavel b9 na dimensao LD2 consegue se sobresair sobre as outras concentracoes. *

## Passo 4. Interpretacao das Funcoes discriminantes:

A) Avaliar os centroides
```{r}
escores<-predict(mod, treino)$x
resulta<-data.frame(predict(mod, treino)$x,
                    class = predict(mod,treino)$class)
centroides <-data.frame(
  LD1=tapply(resulta$LD1, resulta$class, mean),
  LD2=tapply(resulta$LD2, resulta$class, mean),
  LD3=tapply(resulta$LD3, resulta$class, mean))
centroides
```

B) Verificando se os centroides sao significativamente distintos entre si
```{r}
summary.aov(manova(escores ~ treino$class))
```

C) Grafico dos dois primeiros eixos da LDA:
```{r}
ggplot(resulta, aes(x=LD1, y=LD2, color=class))+
  geom_point(size=4)+
  stat_ellipse()+
  geom_point(data=centroides, aes(x=LD1, y=LD2), color="black",size=8, shape=3)+
  theme_classic()+
  geom_hline(yintercept = 0)+
  geom_vline(xintercept = 0)
```

### Questao 6: Interprete os resultados: Quais grupos sao bem distintos? Quais aparentam ser mais semelhantes? Explique.

**R**: * Os grupos D e O, aparentam ser os mais distintos entre os grupos de arvores*

## Passo 5: Testar o modelo com os dados de teste (validacao cruzada)
```{r}
pred <- predict(mod,teste)$class
real <- teste$class
table(pred, real)
confusionMatrix(xtab)
```

### Questao 7: A funcao discriminante foi bem sucedida em separar as classes usando as variaveis independentes? 
**R**: *Cerca 20% dos resultados foram falhos, contudo acredito que o modelo seja satisfatorio, por evidenciar uma proporcao simetrica entre os erros do tipo um e do tipo dois.*


### Quest?o 8: Quais as vantagens e desvantagens da regressao logistica em relacao a analise discriminante?
**R**: *A regressao logistica é recomendada em situaçãoes nas quais a variavel dependente é binária justamente pelo fato da variavel resposta adotar um comportamento deterministico, enquanto discriminante apresenta uma analise classificatorios. Ao contrário de regressão discriminante, regressão logística pode ser usado somente para prever funções discretas. Portanto, a variável dependente da análise  se limita a um conjunto discreto. Tendo a Regressao Logistica como vantagens : Facilidade para lidar com variáveis independentes categóricas, fornece resultados em termos de probabilidade, facilidade de classificação de indivíduos em categorias, requer pequeno número de suposições o que lhe garante uma alto grau de confiabilidade.*
