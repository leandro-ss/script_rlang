---
title: "LDA - Linear Discriminant Analysis"
author: "J van Melis"
date: "2 de setembro de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Analise de Discriminantes Lineares (ou LDA - Linear Discriminant Analysis)

## Introdu??o geral

A LDA ? uma t?cnica cl?ssica de an?lise multivariada, que tem como principais **aplica??es**:

 - Discriminar e Classificar objetos em grupos pr?-definidos (2 ou mais grupos)
 - Definir se os meus grupos conseguem ser bem distintos para os objetos analisados
 - Encontrar o poder discriminat?rio dentre as vari?veis, verificando a import?ncia que uma vari?vel 
 
A **Regress?o Log?stica** tamb?m tem o objetivo de usar vari?veis independentes e produzir como resposta o grupo a qual um objeto pertence (1 ou 0, p.ex), mas a LDA:

  - Usa regress?o linear mas ? interpretada de maneira diferente (Grupos ~ X1 + X2...Xn), pois os "eixos s?o simplificados" (Fun??es Discriminantes que s?o constru?das a partir das vari?veis)
  - Funciona para separar 2 ou mais grupos.
  
A LDA  e **An?lises de Agrupamentos** (Clustering) s?o semelhantes, pois tem como objetivo a separa??o dos objetos em grupos, mas:

  - Ao contr?rio do clustering, na LDA os grupos j? s?o conhecidos (clustering ? ?til para encontrar esses grupos, baseando-se na similaridade entre as observa??es);
  - Pode ser usado para classificar novas observa??es que contenham as mesmas vari?veis utilizadas que foram utilizadas para construir as Fun??es Discriminates (clustering faz a classifica??o para o que foi observado).
  
E, finalmente, a LDA ? diferente da **An?lise de Componentes Principais** pois, apesar de haver a constru??o de uma nova vari?vel que simplifica as vari?veis independentes analisadas, a LDA:
  
  - ? mais interessada nos grupos e n?o em estudar as vari?veis independentes;
  - ? focada em maximizar  a separa??o de grupos conhecidos, enquanto que a PCA foca em reduzir as dimens?es dos dados;
  - O total de vari?veis constru?das ser? sempre o n?mero de grupos - 1.
  
Portanto, a LDA tem como principais **objetivos**:

 - Observar se existem diferen?as de grupos em perfil multivariado
 - Escolher vari?veis independentes que ajudem a explicar o m?ximo de diferen?as no escores dos grupos
 - Estabelecer procedimentos para classificar objetos basendo-se em um conjunto de vari?veis independentes

## Pressupostos da LDA

Os principais pressupostos para essa an?lise ?:

  - Deve ter os **grupos bem estabelecidos**;
  - As vari?veis independentes devem ser **m?tricas** (quantitativas)
  - Essas vari?veis independentes devem seguir **distribui??o normal** (mas cuidados podem ser feitos)
  - As vari?veis devem mostrar-se com **linearidades**;
  - **Colinearidades muito altas** devem ser evitadas;
  - As **matrizes de vari?ncia-covari?ncia iguais** entre os grupos;
  - O tamanho da **amostra** deve ser consider?vel (1. m?nimo 5 observa??es por vari?vel independente; 2. cada grupo deve ter mais objetos que vari?veis independentes analisadas, 3. grupos com tamanhos semelhantes).
  
## LDA passo-a-passo

Para a execu??o de uma LDA, sabendo claramente de qual ? seu objetivo, o pesquisador deve seguir **6 passos**.

  1. Tamanho da Amostra e Cria??o de amostras "treino" e "teste"

  2. Sele??o e An?lise das vari?veis independentes

  3. Estima??o e Avalia??o das Fun??es Discriminantes

  4. Interpreta??o das Fun??es Discriminantes

  5. Valida??o Cruzada

  6. Conclus?es

A seguir, executaremos esses 6 passos com o banco de dados de `iris`:

```{r}
data("iris")
```

e usaremos a fun??o `lda` do pacote `MASS`. A saber que ainda existem os pacotes `ade4` e `candisc` que podem executar LDA.

```{r}
if(!require(MASS)){install.packages('MASS')}
```

### 1. Considera??o quanto ao tamanho da Amostra 

Primeiramente, verifique quantos objetos tem em cada grupo:

```{r}
table(iris$Species)
```

Como mant?m um n?mero razo?vel por grupo (50) e s? temos 4 vari?veis independentes, podemos fazer uma divis?o 50:50 para amostras "treino" e "teste", ou at? um pouco maior para "treino" e o restante para "teste" (2:1, por exemplo).
Para isso, farei um sorteio de 2/3 do total para "treino" e o restante (1/3) para "teste":

```{r}
set.seed(51)
n<-length(iris$Species) # quantos objetos existem
sorteio <- sample(1:n, size=n/3)
teste <- iris[-sorteio,]
treino<- iris[sorteio,]
table(teste$Species)
table(treino$Species)
```

As propor??es ficaram um pouco diferentes, se quiser testar se as propor??es s?o semelhantes, voc? pode aplicar um teste de propor??es com $\chi^2$:

Para teste:

```{r}
n.teste<-as.numeric(table(teste$Species))
teste.prop<-n.teste/100
prop.test(teste.prop, rep(100/3, 3))
```

Para treino:

```{r}
n.treino<-as.numeric(table(treino$Species))
treino.prop<-n.treino/sum(n.treino)
prop.test(treino.prop, rep(sum(n.treino)/3, 3))
```

Ambas as propor??es seguem a distribui??o nula (as propor??es s?o iguais com as propor??es originais, pois para ambos os p-value foram maiores que 0.05)


### 2. Sele??o de vari?veis independentes

Caso voc? tenha muitas vari?veis (mais do que tem de observa??es em cada grupo), ? interessante reduzir a quantidade de vari?veis a serem utilizadas.
O procedimeto a ser utilizado pode ser por avalia??o das vari?veis por seus pressupostos e correla??es, mas tamb?m pode ser utilizado o procedimento de *stepwise*. 

Para cr?ticas e sugest?es para efetuar uma LDA com *stepwise* com o R, sugiro a leitura de alguns links, mas resumidamente podemos considerar:

  - Quando existem muitas vari?veis preditoras.

  - Geralmente o conjunto reduzido ? t?o bom - ou melhor - que a totalidade das vari?veis.

  - ? menos est?vel e generaliz?vel a medida que a propor??o entre amostra e vari?vel independente ? menor que 20.

  - Selecionar vari?veis independentes em uma modelagem sem ter nenhuma hip?tese *a priori* pode levar a fal?cias l?gicas ou correla??es esp?rias (al?m de outros erros).

[1](https://doi:10.1111/j.1399-3054.2010.01431.x) Kozak, M., & Azevedo, R. (2011). Does using stepwise variable selection to build sequential path analysis models make sense? Physiologia plantarum, 141(3), 197-200.  

[2](https://doi:10.1111/j.1365-2656.2006.01141.x) Whittingham, M. J., Stephens, P., Bradbury, R. B., & Freckleton, R. P. (2006). Why do we still use stepwise modelling in ecology and behaviour? The Journal of animal ecology, 75(5), 1182-9. 

[3](https://www.rdocumentation.org/packages/klaR/versions/0.6-14/topics/stepclass) Pacote `klaR` com a fun??o `stepclass()`


No exemplo de `iris`, s? temos 4 vari?veis: `Sepal.Length`, `Sepal.Width`, `Petal.Length` e `Petal.Width`, que s?o o comprimento (*length*) e largura (*width*) das s?palas (estuturas coloridas mais externas dessa flor, *sepal*) e p?talas (estruturas mais internas, que s?o menores que as s?palas nesse g?nero de flores, *petal*).

A seguir, exploraremos os pressupostos das vari?veis independentes: (A) Normalidade , (B) Linearidade das rela??es, (C) Multicolinearidade, (D) Igualdade das Matrizes de dispers?o entre grupos:

#### A. Normalidade das vari?veis independentes

Podemos utilizar de an?lise visual/gr?fica (QQ-Plot) e/ou estat?stica (Teste de Shapiro-Wilk) para isso:

Testando a normalidade da vari?vel `Sepal.Length` para cada esp?cie de `iris`:

```{r}
tapply(treino$Sepal.Length, 
         treino$Species, 
         shapiro.test)
```

Testando a normalidade da vari?vel `Sepal.Width` para cada esp?cie de `iris`

```{r}
tapply(treino$Sepal.Width, 
         treino$Species, 
         shapiro.test)
```

Testando a normalidade da vari?vel `Petal.Length` para cada esp?cie de `iris`

```{r}
tapply(treino$Petal.Length, 
         treino$Species, 
         shapiro.test)
```

Testando a normalidade da vari?vel `Petal.Width` para cada esp?cie de `iris`

```{r}
tapply(treino$Petal.Width, 
         treino$Species, 
         shapiro.test)
```


QQ-plot de todas as vari?veis, nas linhas s?o as esp?cies (1 a 3) e nas colunas as vari?veis (de 1 a 4):

```{r}
par(mfrow=c(3,4))
species<-levels(treino$Species)
for (i in 1:3){
  for (j in 1:4){
    qqnorm(treino[,j][treino$Species==species[i]])
    qqline(treino[,j][treino$Species==species[i]], col="red")
  }
}
```

Somente a `Sepal.Width` da esp?cie `setosa` que n?o apresenta normalidade. Mas considerando que avaliamos 12 conjuntos de vari?veis (3 esp?cies e 4 vari?veis independentes) e somente 1 mostrou algum desvio, tudo bem se seguirmos.

Ter?amos problemas maiores se todas ou maior parte das vari?veis para 1 esp?cie n?o mostrasse distribui??o normal ou se uma ou mais vari?veis n?o mostrarem distribui??o normal para todas as esp?cies. N?o ? o nosso caso

#### B. Linearidade de rela??es

Fa?a uma verifica??o visual das rela??es entre as vari?veis, para ver se alguma das rela??es mostra-se com alguma rela??o nao linear (p.ex: quadr?tica, exponencial, etc).
Pessoalmente, gosto de fazer essa an?lise visual com o pacote `GGally` , muito similar ao `ggplot2`:

```{r, include=F}
if(!require(GGally)){install.packages("GGally")}
```


```{r}
GGally::ggpairs(treino, aes(colour = Species, alpha = 0.4))+theme_bw()
```

#### C. Falta de multicolinearidade entre vari?veis independentes

Para isso, ? importante verificar a correla??o entre as vari?veis. Pelo gr?fico anterior j? pudemos perceber que `Petal.Width` e `Petal.Length` s?o altamente correlacionadas:

```{r}
cor(treino[,1:4])
```
A qual podemos verificar pela correla??o alta = `r cor(treino$Petal.Width, treino$Petal.Length)`.

Se tiv?ssemos muitas vari?veis, essas duas vari?veis poderiam ser sintetizadas em uma ?nica, portanto voc? poderia utilizar somente `Petal.Width` ou `Petal.Length`, por exemplo.
N?s manteremos o uso das duas vari?veis, pois o nosso modelo LDA pode perder poder de discrimina??o se usarmos poucas vari?vels.

#### D. Matrizes de dispers?o iguais

As Matrizes de vari?ncias-covari?ncias devem ser iguais entre os grupos. Para isso, podemos executar o teste M de Box. Para executarmos uma LDA, amostras pequenas e matrizes de covari?ncia desiguais afetam negativamente a signific?ncia do processo de estima??o das fun??es discriminantes.

O pacote `biotools` possui a fun??o `boxM()` para que possamos executar esse teste:

```{r, include=F}
if(!require(biotools)){install.packages("biotools")}
```

```{r}
biotools::boxM(treino[,1:4],treino$Species)
```

Infelizmente o teste M de Box (Box's M test) ? muito sens?vel ? viola??es da normalidade, levando a rejei??o de grande parte dos casos, que ? o nosso caso (p-value <0.01, logo rejeitamos a hip?tese nula de que as matrizes s?o iguais entre os grupos).

Quando as matrizes s?o diferentes, a sugest?o ? (i) utilizar QDA ao inv?s de LDA ou (ii) fazermos uma valida??o cruzada dos dados, com a separa??o das amostras emm `treino` e em `teste`, como fizemos, e testar se o modelo constru?do tem um bom ajuste (verificar tabela confus?o)

### 3. Estima??o e Avalia??o das Fun??es Discriminantes

No R existem muitos pacotes e maneira de realizar uma lda. Pessoalmente, prefiro a fun??o `lda()` do pacote `MASS`, pois tem um *output* limpo e a forma de escrever a fun??o ? muito parecida com um modelo linear (`lm()` ou `glm()`):

```{r, include=F}
if(!require(MASS)){install.packages("MASS")}
```


```{r}
dis1 <- MASS::lda(Species~., data = treino)
dis2 <- MASS::lda(Species~., data = treino, CV=TRUE) # cross-validation
```

com o argumento `CV=TRUE`, a fun??o `lda()` executa um *cros-validation*. A principal diferen?a de *output* ? que com `CV=TRUE` h? uma tabela no resultado da LDA chamado `posterior` (`dis2$posterior`), que s?o as **probabilidades** de serem classificadas em cada uma das esp?cies (*Iris setosa*, *I. versicolor* e *I. virginica*) pela FD (fun??o de Classifica??o, tamb?m chamada de Fun??o Discriminante Linear de Fisher) constru?da.

Esse objeto `posterior` ? muito semelhante (se a sua FD estiver boa) com o resultado da aplica??o da FD nos dados inseridos (`predict(dis1)`), que tamb?m possui uma tabela `posterior`, com as probabilidades de cada observa??o pertencer a um determinado grupo (`setosa`, `versicolor` ou `virginica`):

```{r}
previsto <- predict(dis1)
head(round(previsto$posterior,4))
```

Essas probabilidades s?o obtidas pelos valores das fun??es discriminantes (escores) obtidas para cada objeto (observa??o). Esses valores podem ser obtidos na tabela `x` do objeto `previsto` (resultante do `predict(dis1)`)

```{r}
escores <- predict(dis1)$x
head(escores)
```

Lembrando que s?o constru?dos um n?mero de $N-1$ fun??es discriminantes, sendo $N$ o n?mero de grupos existentes. No nosso caso, foram constru?dos 2 pois temos 3 grupos (esp?cies): LD1 e LD2.

Os escores dessas fun??es discriminantes (`LD1` e `LD2`) s?o importantes para fazer as separa??es dos grupos. O escore discriminante ? `0` para cada um dos LD, portanto, cada grupo ? separado pelo seu sinal. A primeira LD (`LD1`) separa 1 grupo do restante dos grupos. Um objeto ser? classificado de 1 grupo determinado se apresentar valor positivo ou pertencer? ao restante se apresentar valor negativo. As LDs s?o sendo constru?das at? conseguirmos separar todos os grupos do restante. Por isso que o n?mero de LDs ser? $N-1$. 

O pr?ximo passo ? fazer a avali??o da precis?o preditiva, para isso ? constru?do uma matriz confus?o, contrastando o que ? previsto pelo modelo e a qual grupo que pertence realmente aquela observa??o:

```{r}
grupos_previstos <- predict(dis1)$class
grupos_reais <-  treino$Species
tabela<-table(grupos_previstos, grupos_reais)
tabela
```


Para observamos as porcentagens de acertos, verificamos a m?dia da diagonal da matriz confus?o:

```{r}
mean(
  diag(tabela)/
  table(grupos_reais)
  ) 
```

### 4. Interpreta??o das Fun??es Discriminantes

Para isso ser? necess?rio ver os escores das **cargas discriminantes** (correla??es das vari?veis independentes com as LD -fun??es discriminantes - constru?das). os valores est?o contidos no objeto resultante da `lda()` na tabela `scaling`:

```{r}
dis1$scaling
```

Portanto, quanto **maior** o escore de LD1 para um objeto (observa??o), **maior** ? o comprimento da S?pala, por?m **menor** para a largura da P?tala, pois as correla??es s?o positiva e negativa respectivamente de `LD1` com `Sepal.Length` e `Petal.Width`.

Para melhor interpretarmos como foi feita a classifica??o segundo essas fun??es discriminates, podemos ver os Centroides dos grupos

```{r}
escores<-predict(dis1, treino)$x
resulta<-data.frame(predict(dis1, treino)$x,
                    species = predict(dis1,treino)$class)
centroides<-data.frame(
  LD1=tapply(resulta$LD1, resulta$species, mean),
  LD2=tapply(resulta$LD2, resulta$species, mean))
centroides

```

Ou seja, a primeira LD discriminou `setosa` do restante (valores positivos pertencem a `setosa` e valores negativos pertecem ?s outras duas esp?cies) e a segunda LD discriminou entre `versicolor` (valores positivos) e `virginica` (valores negativos).

Podemos observar com o gr?fico dos escores e seus centr?ides (+) para cada esp?cie:

```{r}
ggplot(resulta, aes(x=LD1, y=LD2, color=species))+
  geom_point(size=4)+
  stat_ellipse()+
  geom_text(data=centroides, aes(x=LD1+1.5, y=LD2+0.1, label=species), color="black")+
  geom_point(data=centroides, aes(x=LD1, y=LD2), color="black",size=8, shape=3)+
  theme_classic()+
  geom_hline(yintercept = 0)+
  geom_vline(xintercept = 0)

```

Para verificar se as LDs apresentam signific?ncia, podemos utilizar o valor de Lambda de Wilk:
Testa a significancia estatistica do poder discriminat?rio da(s) fun??o(?es) discriminante(s). Wilks' lambda: varia de 1.0 (sem poder discriminatorio) ate 0.0 (poder discriminatorio perfeito).
A hip?tese nula neste caso ? que *n?o h? diferen?a significativa entre os centroides dos grupos*

```{r}
escores<-predict(
  lda(Species~.,data=treino)
                 )$x # valores de FD para observacao
real <- treino$Species
summary.aov(manova(escores ~ real),test="Wilks")
```

Para ambas func?es (LD1 e LD2) foi significativo, ou seja, os centroides dos grupos s?o diferentes entre si.


### 5. Valida??o Cruzada

Podemos verificar se a nossa amostra `teste` tamb?m responder? com um bom desempenho para a FD constru?da com os dados de `treino` (verificando o *overfitting*):

```{r}
grupos_previstos <- predict(dis1, teste)$class
grupos_reais <-  teste$Species
tabela <- table(grupos_previstos, grupos_reais)
tabela
```

Para observamos as porcentagens de acertos, verificamos a m?dia da diagonal da matriz confus?o:

```{r}
mean(
  diag(tabela)/
  table(grupos_reais)
  ) 
```


### 6. Conclus?es

Qual grupo mostra discrimina??o clara e significante para a primeira **fun??o discriminante**?

Quais vari?veis independentes mostraram coeficientes (**Cargas Fatoriais** ou **Peso Discriminante**) positivos ou negativos com essa primeira fun??o discrimiante?

Qual ? a sua conclus?o, baseando-se nas duas respostas anteriores? Ou seja, qual esp?cie apresenta p?talas/s?palas menores/maiores e estreitas/largas? 